<!DOCTYPE html>
<html lang="uk">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üöÄ AI Meeting Recorder</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
        }
        .container {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
            width: 100%;
            box-sizing: border-box;
        }
        h1 {
            text-align: center;
            margin-bottom: 30px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }
        .input-group {
            margin-bottom: 20px;
        }
        .input-group label {
            display: block;
            margin-bottom: 5px;
            font-weight: bold;
        }
        .input-group input {
            width: 100%;
            padding: 10px;
            border: none;
            border-radius: 5px;
            background: rgba(255, 255, 255, 0.9);
            color: #333;
            box-sizing: border-box;
        }
        .chunk-duration, .controls, .log-section {
            text-align: center;
            margin-top: 20px;
        }
        .log {
            background: rgba(0, 0, 0, 0.3);
            border-radius: 10px;
            padding: 20px;
            height: 200px;
            overflow-y: auto;
            font-family: 'Courier New', monospace;
            white-space: pre-wrap;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
        .status {
            text-align: center;
            font-size: 18px;
            margin: 20px 0;
            font-weight: bold;
        }
        .recording {
            color: #ff6b6b;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        button {
            font-size: 18px;
            padding: 15px 30px;
            margin: 10px;
            border: none;
            border-radius: 10px;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
        }
        .start-btn {
            background: linear-gradient(45deg, #28a745, #20c997);
            color: white;
        }
        .stop-btn {
            background: linear-gradient(45deg, #dc3545, #e74c3c);
            color: white;
	.pause-btn {
            background: linear-gradient(45deg, #FFEB3B, #FFC107);
            color: white;
        }
        .clear-btn {
            background: linear-gradient(45deg, #6c757d, #495057);
            color: white;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üöÄ –ó–∞–ø–∏—Å –∞—É–¥—ñ–æ —É WAV –¥–ª—è Telegram</h1>

        <div class="input-group">
            <label for="meetingName">–ù–∞–∑–≤–∞ –∑—É—Å—Ç—Ä—ñ—á—ñ:</label>
            <input type="text" id="meetingName" placeholder="–í–≤–µ–¥—ñ—Ç—å –Ω–∞–∑–≤—É –∑—É—Å—Ç—Ä—ñ—á—ñ">
        </div>

        <div class="chunk-duration">
            <label>–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å —á–∞—Å—Ç–∏–Ω–∏: <span id="durationValue">30</span> —Å–µ–∫—É–Ω–¥</label><br>
            <input type="range" id="chunkDuration" min="10" max="900" value="600" step="5">
        </div>

        <div class="status" id="status">‚ñ∂Ô∏è –ì–æ—Ç–æ–≤–∏–π –¥–æ –∑–∞–ø–∏—Å—É</div>

        <div class="controls">
            <button class="start-btn" id="startBtn">üé§ –°—Ç–∞—Ä—Ç</button>
            <button class="pause-btn" id="pauseBtn">‚è∏ –ü–∞—É–∑–∞</button>
            <button class="stop-btn" id="stopBtn" disabled>üö© –°—Ç–æ–ø</button>
            <button class="clear-btn" id="clearLogsBtn">üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç–∏ –ª–æ–≥–∏</button>
        </div>

        <div class="log-section">
            <div class="section-title">üìù –ñ—É—Ä–Ω–∞–ª –ø–æ–¥—ñ–π</div>
            <div class="log" id="log">–ì–æ—Ç–æ–≤–∏–π –¥–æ —Ä–æ–±–æ—Ç–∏...</div>
        </div>
    </div>

    <script>
        const FIXED_BOT_TOKEN = "7559425067:AAEoI0api5HvyDGOulacrGcqNHAT0fqwHcE";
        const FIXED_CHAT_ID = "-1002576413834";

        class AudioRecorderApp {
            constructor() {
                this.isRecording = false;
                this.mediaRecorder = null;
                this.chunkCounter = 0;
                this.endSession = false;
                this.initializeElements();
                this.setupEventListeners();
            }
            initializeElements() {
                this.startBtn = document.getElementById('startBtn');
                this.stopBtn = document.getElementById('stopBtn');
                this.pauseBtn = document.getElementById('pauseBtn');
                this.status = document.getElementById('status');
                this.log = document.getElementById('log');
                this.chunkDuration = document.getElementById('chunkDuration');
                this.durationValue = document.getElementById('durationValue');
                this.clearLogsBtn = document.getElementById('clearLogsBtn');
                this.meetingNameInput = document.getElementById('meetingName');
            }
            setupEventListeners() {
                this.startBtn.addEventListener('click', () => this.startRecording());
                this.stopBtn.addEventListener('click', () => this.stopRecording());
                this.pauseBtn.addEventListener('click', () => this.pauseRecording());
                this.chunkDuration.addEventListener('input', (e) => {
                    this.durationValue.textContent = e.target.value;
                });
                this.clearLogsBtn.addEventListener('click', () => {
                    this.log.textContent = '–õ–æ–≥–∏ –æ—á–∏—â–µ–Ω–æ...\n';
                });
            }
            logMessage(message) {
                const timestamp = new Date().toLocaleTimeString('uk-UA');
                this.log.textContent += `\n[${timestamp}] ${message}`;
                this.log.scrollTop = this.log.scrollHeight;
            }
            async startRecording() {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        }
                    });
                    this.isRecording = true;
                    this.endSession = false;
                    this.chunkCounter = 0;
                    this.startBtn.disabled = true;
                    this.stopBtn.disabled = false;
                    this.status.textContent = 'üî¥ –ó–∞–ø–∏—Å –∞–∫—Ç–∏–≤–Ω–∏–π...';
                    this.status.classList.add('recording');
                    this.logMessage('üî¥ –ó–∞–ø–∏—Å —Ä–æ–∑–ø–æ—á–∞—Ç–æ...');
                    this.startChunkRecording(stream);
                } catch (error) {
                    this.logMessage(`‚ùå –ü–æ–º–∏–ª–∫–∞ –¥–æ—Å—Ç—É–ø—É –¥–æ –º—ñ–∫—Ä–æ—Ñ–æ–Ω–∞: ${error.message}`);
                }
            }
            pauseRecording() {
                this.isRecording = false;
                this.logMessage('‚è∏ –ü–∞—É–∑–∞ –Ω–∞—Ç–∏—Å–Ω—É—Ç–∞');
                if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
                    this.mediaRecorder.stop();
                }
                this.startBtn.disabled = false;
                this.stopBtn.disabled = false;
                this.status.textContent = '‚è∏ –ó–∞–ø–∏—Å –ø—Ä–∏–∑—É–ø–∏–Ω–µ–Ω–æ';
                this.status.classList.remove('recording');
            }
            stopRecording() {
                this.isRecording = false;
                this.endSession = true;
                if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
                    this.mediaRecorder.stop();
                }
                this.startBtn.disabled = false;
                this.stopBtn.disabled = true;
                this.pauseBtn.disabled = true;
                this.status.textContent = '‚èπÔ∏è –ó–∞–ø–∏—Å –∑—É–ø–∏–Ω–µ–Ω–æ';
                this.status.classList.remove('recording');
                this.logMessage('‚èπÔ∏è –ó–∞–ø–∏—Å –∑—É–ø–∏–Ω–µ–Ω–æ –∑ –ø–æ–∑–Ω–∞—á–∫–æ—é END');
            }
            startChunkRecording(stream) {
                if (!this.isRecording) return;
                const chunks = [];
                this.mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus'
                });
                this.mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        chunks.push(event.data);
                    }
                };
                this.mediaRecorder.onstop = async () => {
                    const webmAudioBlob = new Blob(chunks, { type: 'audio/webm' });
                    const timestamp = Date.now();
                    this.logMessage(`‚è≥ –ö–æ–Ω–≤–µ—Ä—Ç—É—é WebM –≤ WAV –¥–ª—è –≤—ñ–¥–ø—Ä–∞–≤–∫–∏...`);
                    try {
                        const wavAudioBlob = await this.convertWebmToWav(webmAudioBlob);
                        await this.sendAudioToTelegram(wavAudioBlob, timestamp);
                    } catch (conversionError) {
                        this.logMessage(`‚ùå –ü–æ–º–∏–ª–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó: ${conversionError.message}`);
                    }
                    if (this.isRecording) {
                        setTimeout(() => this.startChunkRecording(stream), 500);
                    }
                };
                this.mediaRecorder.start();
                this.chunkCounter++;
                this.logMessage(`üéµ –ó–∞–ø–∏—Å —á–∞—Å—Ç–∏–Ω–∏ ${this.chunkCounter} (${this.chunkDuration.value}—Å)...`);
                setTimeout(() => {
                    if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
                        this.mediaRecorder.stop();
                    }
                }, parseInt(this.chunkDuration.value) * 1000);
            }
            async sendAudioToTelegram(audioBlob, timestamp) {
                const formData = new FormData();
                const baseName = this.meetingNameInput.value.trim() || 'audio';
                const filename = `${baseName.replace(/[^a-zA-Z0-9_\-]/g, '_')}_${timestamp}${this.endSession ? '_END' : ''}.wav`;
                formData.append('audio', audioBlob, filename);
                formData.append('chat_id', FIXED_CHAT_ID);
                const url = `https://api.telegram.org/bot${FIXED_BOT_TOKEN}/sendAudio`;
                try {
                    this.logMessage(`üì§ –í—ñ–¥–ø—Ä–∞–≤–ª—è—é ${filename} –≤ Telegram...`);
                    const response = await fetch(url, {
                        method: 'POST',
                        body: formData
                    });
                    const result = await response.json();
                    if (response.ok && result.ok) {
                        this.logMessage(`‚úÖ –ê—É–¥—ñ–æ —É—Å–ø—ñ—à–Ω–æ –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ: ${filename}`);
                    } else {
                        this.logMessage(`‚ùå –ü–æ–º–∏–ª–∫–∞ –≤—ñ–¥–ø—Ä–∞–≤–∫–∏: ${result.description || '–ù–µ–≤—ñ–¥–æ–º–∞'}`);
                    }
                } catch (error) {
                    this.logMessage(`‚ùå –ü–æ–º–∏–ª–∫–∞ –º–µ—Ä–µ–∂—ñ: ${error.message}`);
                }
            }
            async convertWebmToWav(webmBlob) {
                return new Promise((resolve, reject) => {
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const fileReader = new FileReader();
                    fileReader.onload = async () => {
                        try {
                            const audioBuffer = await audioContext.decodeAudioData(fileReader.result);
                            const offlineAudioContext = new OfflineAudioContext(
                                audioBuffer.numberOfChannels,
                                audioBuffer.length,
                                audioBuffer.sampleRate
                            );
                            const source = offlineAudioContext.createBufferSource();
                            source.buffer = audioBuffer;
                            source.connect(offlineAudioContext.destination);
                            source.start(0);
                            const renderedBuffer = await offlineAudioContext.startRendering();
                            const wavData = this.encodeWAV(renderedBuffer, audioBuffer.sampleRate, audioBuffer.numberOfChannels);
                            const wavBlob = new Blob([wavData], { type: 'audio/wav' });
                            resolve(wavBlob);
                        } catch (e) {
                            reject(e);
                        }
                    };
                    fileReader.onerror = (e) => reject(e);
                    fileReader.readAsArrayBuffer(webmBlob);
                });
            }
            encodeWAV(audioBuffer, sampleRate, numChannels) {
                const dataLength = audioBuffer.length * numChannels * 2;
                const buffer = new ArrayBuffer(44 + dataLength);
                const view = new DataView(buffer);
                let offset = 0;
                this.writeString(view, offset, 'RIFF'); offset += 4;
                view.setUint32(offset, 36 + dataLength, true); offset += 4;
                this.writeString(view, offset, 'WAVE'); offset += 4;
                this.writeString(view, offset, 'fmt '); offset += 4;
                view.setUint32(offset, 16, true); offset += 4;
                view.setUint16(offset, 1, true); offset += 2;
                view.setUint16(offset, numChannels, true); offset += 2;
                view.setUint32(offset, sampleRate, true); offset += 4;
                view.setUint32(offset, sampleRate * numChannels * 2, true); offset += 4;
                view.setUint16(offset, numChannels * 2, true); offset += 2;
                view.setUint16(offset, 16, true); offset += 2;
                this.writeString(view, offset, 'data'); offset += 4;
                view.setUint32(offset, dataLength, true); offset += 4;
                for (let i = 0; i < audioBuffer.length; i++) {
                    for (let channel = 0; channel < numChannels; channel++) {
                        let sample = audioBuffer.getChannelData(channel)[i];
                        const s = Math.max(-1, Math.min(1, sample));
                        view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
                        offset += 2;
                    }
                }
                return buffer;
            }
            writeString(view, offset, string) {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            }
        }
        document.addEventListener('DOMContentLoaded', () => {
            new AudioRecorderApp();
        });
    </script>
</body>
</html>
